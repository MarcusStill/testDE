{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Тестовое задание на позицию Data Engineer.\n",
        "\n",
        "Задание включает в себя 3 небольших задачи. В каждой задаче **рекомендуется** оставлять комментарии, код должен быть оформлен согласно **PEP8**. Задания необходимо выполнить без использования Pandas и готовых библиотек для API Яндекс.Погоды.\n",
        "\n",
        "**Перед выполнением тестового задания, необходимо скопировать notebook к себе на диск, и выполнять тестовое в своей копии**."
      ],
      "metadata": {
        "id": "3ffM1IGEysic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_WEmA6DmwZQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "####1. Выгрузка данных из API Яндекс.Погоды и преобразование их в csv\n",
        "\n",
        "Используя API Яндекс.Погоды, необходимо выгрузить прогнозные данные за 7 дней для Москвы, Казани, Санкт-Петербурга, Тулы и Новосибирска. В случае, если API отдает пустые значения за день, то их необходимо удалить.\n",
        "\n",
        "Информация должна быть представлена по часам с расширенным набором полей по осадкам.\n",
        "\n",
        "Полученный json необходимо преобразовать в csv, формат:\n",
        "\n",
        "\\begin{array}{ccc}\n",
        "\\text{city}, \\text{date}, \\text{hour}, \\text{temperature_c}, \\text{pressure_mm}, \\text{is_rainy} \\\\\n",
        "Moscow, 19.08.2023, 12, 27, 750, 0 \\\\\n",
        "Moscow, 19.08.2023, 13, 27, 750, 0 \\\\\n",
        "... \\\\\n",
        "Kazan, 19.08.2023, 12, 20, 770, 1 \\\\\n",
        "Kazan, 19.08.2023, 13, 21, 770, 0 \\\\\n",
        "\\end{array}\n",
        "\n",
        "**Описание полей:**\n",
        "\n",
        "city - Город\n",
        "\n",
        "date - Дата события\n",
        "\n",
        "hour - Часы\n",
        "\n",
        "temperature_c - Температура в Цельсиях\n",
        "\n",
        "pressure_mm - Давление в мм ртутного столба\n",
        "\n",
        "is_rainy - Флаг наличия дождя в конкретный день и час (см. документацию по API - описание полей).\n",
        "\n",
        "Полученный csv необходимо выгрузить на облачный диск и в конце решения предоставить ссылку.\n",
        "\n",
        "**Ссылка на получение ключа:** https://yandex.ru/dev/weather/doc/dg/concepts/about.html#about__onboarding\n",
        "\n",
        "\n",
        "**Дополнительно ответьте на вопросы:** какие существуют возможные пути ускорения получения данных по API и их преобразования? Возможно ли эти способы использовать в Airflow?"
      ],
      "metadata": {
        "id": "-bzGaxhZy3pd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Any\n",
        "\n",
        "import requests\n",
        "from requests import Response\n",
        "\n",
        "\n",
        "def get_weather_data(lat: str, lon: str) -> Any:\n",
        "    \"\"\"\n",
        "        Функция получает данные о погоде для заданных координат.\n",
        "\n",
        "        Args:\n",
        "            lat (str): Широта.\n",
        "            lon (str): Долгота.\n",
        "\n",
        "        Returns:\n",
        "            dict: Словарь с данными о погоде\n",
        "            или\n",
        "            int: код состояния ответа HTTP.\n",
        "    \"\"\"\n",
        "    # Ключ для подключения к API\n",
        "    access_key: str = 'f427b830-9b36-40da-951e-db33ed3b4ef8'\n",
        "    # Адрес для отправки GET-запросов\n",
        "    url: str = 'https://api.weather.yandex.ru/v2/forecast'\n",
        "    # Устанавливаем параметры запроса\n",
        "    # широта, долгота, язык ответа, срок прогноза в днях, наличие почасового прогноза, подробный прогноз осадков\n",
        "    params: dict[str, int | bool | str] = {\n",
        "        'lat': lat,\n",
        "        'lon': lon,\n",
        "        'lang': 'en_EN',\n",
        "        'limit': 7,\n",
        "        'hours': True,\n",
        "        'extra': True\n",
        "    }\n",
        "    try:\n",
        "        response: Response = requests.get(url, params=params, headers={'X-Yandex-API-Key': access_key})\n",
        "        # Проверяем статус ответа\n",
        "        response.raise_for_status()\n",
        "        return response.json()\n",
        "    except requests.exceptions.HTTPError as err:\n",
        "        # Возвращаем код состояния ответа HTTP\n",
        "        return err.response.status_code\n",
        "    except requests.exceptions.ConnectionError as err:\n",
        "        # Если возникает ошибка подключения, возвращаем соответствующее сообщение\n",
        "        return err\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Создаем словарь для хранения координат населенных пунктов\n",
        "    cities: dict[str, tuple[str, str]] = {\n",
        "        'Moscow': ('55.75396', '37.620393'),\n",
        "        'Kazan': ('55.018803', '82.933952'),\n",
        "        'Saint Petersburg': ('59.937500', '30.308611'),\n",
        "        'Tula': ('54.204838', '37.618492'),\n",
        "        'Novosibirsk': ('55.018803', '82.933952')\n",
        "    }\n",
        "    # Используем контекстный менеджер, чтобы автоматически закрыть файл после завершения операций\n",
        "    with open('cities_weather.csv', mode='w') as file:\n",
        "        for city, (lat, lon) in cities.items():\n",
        "            weather_data: Any = get_weather_data(lat, lon)\n",
        "            if isinstance(weather_data, dict):\n",
        "                for forecast in weather_data['forecasts']:\n",
        "                    for hour in forecast['hours']:\n",
        "                        weather: tuple[Any, Any, Any, Any, Any, Any] = (\n",
        "                            weather_data['geo_object']['locality']['name'],\n",
        "                            forecast['date'],\n",
        "                            hour['hour'],\n",
        "                            hour['temp'],\n",
        "                            hour['pressure_mm'],\n",
        "                            hour['prec_type']\n",
        "                        )\n",
        "                        # Преобразуем каждый элемент кортежа в строку и объединяем их через запятую\n",
        "                        line: str = ','.join(str(item) for item in weather)\n",
        "                        file.write(line + '\\n')\n",
        "            else:\n",
        "                file.write(f'Ошибка при получении данных. Код состояния HTTP: {weather_data}')\n"
      ],
      "metadata": {
        "id": "TAK327i-yuYw",
        "ExecuteTime": {
          "end_time": "2024-05-11T14:23:50.285606Z",
          "start_time": "2024-05-11T14:23:48.927281Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "oD-_o-eZuzwo"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# Для ускорения получения данных по API можно воспозьзоваться следующими вариантами.\n",
        "# 1. Использовать класс session из библиотеки requests для поддержки пула соединений. Это позволит повторно использовать существующие соединения.\n",
        "# 2. Переписать последовательные синхронные запросы на асинхронные. Например, при помощи asyncio или aiohttp.\n",
        "# 3. Использовать кэширование. Это позволит сохранять результаты предыдущих запросов и использовать их при повторных запросах.\n",
        "# 4. Использование NumPy и Pandas. Вероятно они помогут ускорить код при работе с API.\n",
        "#\n",
        "# В Airflow можно использовать PythonOperator для этих целей."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "####2. Загрузка данных в БД (PostgreSQL).\n",
        "\n",
        "Используя полученный csv файл, необходимо загрузить данных в PostgreSQL. Предварительно в БД необходимо создать схемы: для приемки сырых данных и для будущих агрегирующих таблиц.\n",
        "\n",
        "При создании таблиц приветствуется использование партицирования и индексирования (по возможности и необходимости).\n",
        "\n",
        "В решении необходимо показать код загрузки данных, скрипты создания схем и таблиц для пункта 2 и 2.1.\n",
        "\n",
        "Подсказка: для решения задачи нужно развернуть БД, мы рекомендуем это сделать локально с помощью докера."
      ],
      "metadata": {
        "id": "HOAEAH0kzCAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import psycopg2\n",
        "\n",
        "# Креды для подключения к БД. Используем схему raw_data\n",
        "conn = psycopg2.connect(\n",
        "    host=\"localhost\",\n",
        "    dbname=\"postgres\",\n",
        "    user=\"postgres\",\n",
        "    password=\"12345\",\n",
        "    options=f'-c search_path=raw_data',\n",
        ")\n",
        "\n",
        "# Создаем курсор\n",
        "cur = conn.cursor()\n",
        "# Загружаем данные используя контекстный менеджер, чтобы автоматически закрыть файл после завершения операций\n",
        "with open('cities_weather.csv', 'r') as file:\n",
        "    cur.copy_from(file, 'cities_weather', sep=',')\n",
        "# Сохраняем изменения\n",
        "conn.commit()\n",
        "# Закрываем соединение\n",
        "cur.close()\n",
        "conn.close()\n"
      ],
      "metadata": {
        "id": "Isa3SMnxyudM",
        "ExecuteTime": {
          "end_time": "2024-05-11T17:03:31.745211Z",
          "start_time": "2024-05-11T17:03:31.725668Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "ZKUiMcRUuzwo"
      },
      "cell_type": "code",
      "source": [
        "# Создаем схему для сырых данных\n",
        "# CREATE SCHEMA raw_data;\n",
        "\n",
        "# Ddl таблицы cities_weather в БД\n",
        "# CREATE TABLE raw_data.cities_weather (\n",
        "# \tcity varchar(50) NULL,\n",
        "# \t\"date\" varchar(10) NULL,\n",
        "# \t\"hour\" int2 NULL,\n",
        "# \ttemperature_c int2 NULL,\n",
        "# \tpressure_mm int2 NULL,\n",
        "# \tis_rainy int2 NULL\n",
        "# );\n",
        "#\n",
        "# Оптимизация.\n",
        "# Исходя из самых распространенных запросов к таблицам можно было бы создать индексы (например, btree) по тем полям, которые участвуют в этих запросах. И периодически смотреть какие индексы у нас используются, убирать редко используемые и добавлять нужные.\n",
        "# Так же можно использовать секционирование. Например, при использовании Airflow по dag_run_id. Оптимальным будет секционирование по столбцам (или по набору столбцов), которые чаще всего присутствуют в предложении where в запросах, обращающихся к секционируемой таблице."
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "####2.1 Формирование витрин (PostgreSQL).\n",
        "\n",
        "1. Используя таблицу с сырыми данными, необходимо собрать витрину, где для каждого города и дня будут указаны часы начала дождя. Условимся, что дождь может начаться только 1 раз за день в любом из городов.\n",
        "\n",
        "2. Необходимо создать витрину, где для каждого города, дня и часа будет рассчитано скользящее среднее по температуре и по давлению.\n",
        "\n",
        "\n",
        "Полученные запросы необходимо вставить в google colab, а результаты - выгрузить в формате csv/xlsx и выложить в виде ссылки в google colab.\n",
        "\n",
        "Подсказка: если в исходном файле не было факта начала дождя, то необходимо расставить рандомно значения факта дождя в таблице с сырыми данными.\n"
      ],
      "metadata": {
        "id": "kcubMA6zqy5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Создаем схему для витрин\n",
        "# CREATE SCHEMA data_mart;\n",
        "\n",
        "# Создаем представление. В нем используем запрос, в котором выбираем название города, дату и минимальный час (час начала дождя) для каждого дня, когда ожидается дождь (значения 1 или 2).\n",
        "# В документации указано, что поле \"prec_type\" (тип осадков) может принимать следующие значения: 0 — без осадков, 1 — дождь, 2 — дождь со снегом, 3 — снег, 4 — град.\n",
        "# https://yandex.ru/dev/weather/doc/ru/concepts/forecast-rest\n",
        "\n",
        "# CREATE OR REPLACE VIEW data_mart.start_rain\n",
        "# AS SELECT city,\n",
        "#     date,\n",
        "#     min(hour) AS start_rain_hour\n",
        "#    FROM raw_data.cities_weather\n",
        "#   WHERE is_rainy in (1,2)\n",
        "#   GROUP BY city, date;"
      ],
      "metadata": {
        "id": "TopO7d8GvR6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kh4yAvTpuzwp"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# Принцип расчета методом скользящей средней.\n",
        "# Определяется размер окна (количество последовательных данных), которое будет использоваться для вычисления среднего значения. Для каждой точки данных вычисляется среднее значение, используя #\n",
        "# окно. Исходные значения заменяются полученными средними значениями.\n",
        "# Для каждого города выберем трехдневный период. В этом запросе функция AVG используется с оконным выражением. Используем сортировку по городу, дате и часу.\n",
        "# Определяем окно, включающее строки от 1 предыдущей до 1 следующей.\n",
        "\n",
        "# SELECT\n",
        "#     city,\n",
        "#     date,\n",
        "#     hour,\n",
        "#     temperature_c,\n",
        "#     pressure_mm,\n",
        "#     AVG(temperature_c) OVER (\n",
        "#         ORDER BY city,date, hour\n",
        "#         ROWS between 1 preceding and 1 following\n",
        "#     ) AS temp_avg,\n",
        "#     AVG(pressure_mm) OVER (\n",
        "#         ORDER BY city,date, hour\n",
        "#         ROWS between 1 preceding and 1 following\n",
        "#     ) AS press_avg\n",
        "# FROM raw_data.cities_weather\n",
        "# GROUP BY city,date, hour, temperature_c, pressure_mm\n",
        "# order by city,date,hour;"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "####3. Задача на проектирование БД на данных Яндекс.Метрики\n",
        "\n",
        "В функционал Яндекс.Метрики входит возможность выкачивания сырых данных с помощью API: отдельными запросами выкачиваются просмотры и визиты. Для этого процесса необходимо спроектировать базу данных, предусмотрев несколько слоев данных и \"хотелки\" заказчиков: в 90% случаев заказчикам необходимы агрегаты данных (например, построить воронку по визитам на страницах и вводу номеров телефонов в разрезе дат, страниц, utm меток, или построить флоу пользователей в разрезе устройств, ОС, и т.д.).\n",
        "\n",
        "Результат необходимо предоставить в виде схемы с описанием.\n",
        "\n",
        "Ссылки на структуру таблиц:\n",
        "\n",
        "https://yandex.ru/dev/metrika/doc/api2/logs/fields/hits.html\n",
        "\n",
        "https://yandex.ru/dev/metrika/doc/api2/logs/fields/visits.html"
      ],
      "metadata": {
        "id": "88tCFTCbzPv3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z8dugnICyufe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qvvgDAhQyuh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pCi92VAFyukW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}